#!/usr/bin/env python

import apility
import json
import sys
import time
import threatgraph

my_probe="ap-dm-v0"
my_probe_time=1

src, pub = ("apility.io", "apility.io")
probe_id = "apility-domain"
tp = "blacklist"
prob = 0.3

# Get Threat Graph
g = threatgraph.Gaffer()

# Get Apility UUID and get connection
uuid = open("apility-uuid").read().lstrip().rstrip()
a = apility.Apility(uuid)

# Get list of all domains which need to be updated.
domains = g.get_all_domains()
seen_domains = g.get_probed_domains(my_probe)
domains = domains - seen_domains

# Function allows management in chunks
def chunks(l, n):
    l = list(l)
    n = max(1, n)
    return (l[i:i+n] for i in xrange(0, len(l), n))

# Iterate over data chunks
for chunk in chunks(domains, 20):

    print chunk
    
    try:

        # Get reputation
        res = a.get_domain_reputation(chunk)

    except Exception, e:
        print e
        sys.exit(1)


    # Parse results
    rep = {}
    for v in res:
        domain = v["domain"]
        blacks = v["scoring"]["domain"]["blacklist"]
        rep[domain] = blacks

    # Create graph elements
    elts = []

    # Iterate over IPs
    for domain in rep:

        # Iterate over blacklist listings for this domain
        for bl in rep[domain]:

            # Blacklist name
            blacklist = "apility." + bl
            
            # Create a blacklist match edge
            elt = g.make_match_edge(domain, blacklist)
            elts.append(elt)

            # Create a blacklist entity (probably exists already)
            elt = g.make_blacklist_entity(blacklist, prob, tp, src, pub)
            elts.append(elt)

        # Create a probed edge
        elt = g.make_probed_edge(domain, probe_id, my_probe, my_probe_time)
        elts.append(elt)

    # Turn element list into a Gaffer operation
    elts = {
        "class": "uk.gov.gchq.gaffer.operation.impl.add.AddElements",
        "validate": True,
        "skipInvalidElements": False,
        "input": elts
    }

    # Execute Gaffer insert
    url = "/rest/v2/graph/operations/execute"
    data = json.dumps(elts)
    response = g.post(url, data)

    # If status code is bad, fail
    if response.status_code != 200:
        print response.text
        sys.exit(1)

    time.sleep(0.1)

